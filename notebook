{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic Conversational Coherence Metric\n",
        "\n",
        "Reference implementation of the dynamic conversational coherence metric C(t) introduced in:\n",
        "\n",
        "Adolfo J. Céspedes Jiménez (2026)  \n",
        "\"A Minimal Metric for Dynamic Conversational Coherence\"\n",
        "\n",
        "This notebook is fully reproducible and Google Colab–compatible.\n"
      ],
      "metadata": {
        "id": "a4tHyakfKrGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The dataset is used for illustration only. The metric itself is dataset-agnostic.\n"
      ],
      "metadata": {
        "id": "aL8Xaw-sK62c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \"datasets<4\"\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install -U sentence-transformers scikit-learn pandas matplotlib"
      ],
      "metadata": {
        "id": "yNswdLwXenoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "gfQnjAHUetr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"empathetic_dialogues\")\n",
        "print(dataset)\n",
        "print(\"Train size:\", len(dataset[\"train\"]))\n",
        "print(\"Example keys:\", dataset[\"train\"][0].keys())\n"
      ],
      "metadata": {
        "id": "MjwQWm-Ee0p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dialogs_from_empathetic(ds, split=\"train\"):\n",
        "    dialogs = []\n",
        "    current = []\n",
        "    current_conv = None\n",
        "\n",
        "    for row in ds[split]:\n",
        "        if row[\"conv_id\"] != current_conv:\n",
        "            if current:\n",
        "                dialogs.append({\"dialog\": current, \"conv_id\": current_conv})\n",
        "            current = []\n",
        "            current_conv = row[\"conv_id\"]\n",
        "\n",
        "        current.append(row[\"utterance\"])\n",
        "\n",
        "    if current:\n",
        "        dialogs.append({\"dialog\": current, \"conv_id\": current_conv})\n",
        "\n",
        "    return dialogs\n",
        "\n",
        "dialogs_all = build_dialogs_from_empathetic(dataset, split=\"train\")\n",
        "lengths = [len(d[\"dialog\"]) for d in dialogs_all]\n",
        "print(\"Total dialogs:\", len(dialogs_all))\n",
        "print(\"Length stats: min\", min(lengths), \"mean\", round(np.mean(lengths),2), \"max\", max(lengths))\n"
      ],
      "metadata": {
        "id": "xc-lKjd1e4fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogs = dialogs_all[:200]"
      ],
      "metadata": {
        "id": "0DHVhfG2OGh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "-th5HoPLfaC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_dialog(dialog):\n",
        "    return model.encode(dialog, normalize_embeddings=True)\n",
        "\n",
        "def dynamic_coherence(embeddings, alpha=0.7, eps=1e-12):\n",
        "    C = []\n",
        "    memory = embeddings[0].copy()\n",
        "    for t in range(1, len(embeddings)):\n",
        "        C.append(float(np.dot(embeddings[t], memory)))\n",
        "        memory = alpha * memory + (1 - alpha) * embeddings[t]\n",
        "        n = float(np.linalg.norm(memory))\n",
        "        memory = memory / max(n, eps)\n",
        "    return np.array(C, dtype=float)\n",
        "\n",
        "def local_similarity(embeddings):\n",
        "    return np.array([float(np.dot(embeddings[t], embeddings[t-1])) for t in range(1, len(embeddings))], dtype=float)\n",
        "\n",
        "def detect_breaks_topk(signal, p=10, min_k=0, max_k=None):\n",
        "    \"\"\"\n",
        "    Detecta rupturas como las k peores caídas de ΔC.\n",
        "    k = ceil(p% * n_deltas), acotado por [min_k, max_k] si se da.\n",
        "    Permite k=0 si min_k=0 y el diálogo es demasiado corto o si quieres permitir 'sin rupturas'.\n",
        "    \"\"\"\n",
        "    delta = np.diff(signal)\n",
        "    n = len(delta)\n",
        "    if n <= 0:\n",
        "        return np.array([], dtype=int), np.nan, delta\n",
        "\n",
        "    k = math.ceil((p/100) * n)\n",
        "    if max_k is not None:\n",
        "        k = min(k, max_k)\n",
        "    k = max(min_k, k)\n",
        "\n",
        "    if k == 0:\n",
        "        return np.array([], dtype=int), np.nan, delta\n",
        "\n",
        "    idx = np.argsort(delta)[:k]              # k deltas más negativos\n",
        "    breaks = np.sort(idx + 1)                # +1 para mapear a índice en la señal\n",
        "    thr = float(delta[idx[-1]])              # umbral implícito: k-ésimo peor\n",
        "    return breaks, thr, delta\n",
        "\n",
        "def shuffle_dialog(dialog, seed=42):\n",
        "    rng = random.Random(seed)\n",
        "    shuffled = dialog.copy()\n",
        "    rng.shuffle(shuffled)\n",
        "    return shuffled\n"
      ],
      "metadata": {
        "id": "TyCyXJvCfdHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "ALPHA = 0.7\n",
        "P_BREAK = 10\n",
        "MIN_K = 0           # permite 0 rupturas si quieres (recomendado)\n",
        "MAX_K = 3           # cap para no marcar demasiadas en diálogos medianos (ajustable)\n",
        "\n",
        "for i, d in enumerate(dialogs):\n",
        "    dialog = d[\"dialog\"]\n",
        "    n_turns = len(dialog)\n",
        "\n",
        "    # Real\n",
        "    emb = embed_dialog(dialog)\n",
        "    C_dyn = dynamic_coherence(emb, alpha=ALPHA)\n",
        "    C_base = local_similarity(emb)\n",
        "    breaks, thr, delta = detect_breaks_topk(C_dyn, p=P_BREAK, min_k=MIN_K, max_k=MAX_K)\n",
        "\n",
        "    # Control shuffled (mismo contenido, orden aleatorio)\n",
        "    dialog_sh = shuffle_dialog(dialog, seed=SEED + i)\n",
        "    emb_sh = embed_dialog(dialog_sh)\n",
        "    C_dyn_sh = dynamic_coherence(emb_sh, alpha=ALPHA)\n",
        "    C_base_sh = local_similarity(emb_sh)\n",
        "    breaks_sh, thr_sh, delta_sh = detect_breaks_topk(C_dyn_sh, p=P_BREAK, min_k=MIN_K, max_k=MAX_K)\n",
        "\n",
        "    # Métricas agregadas (pero derivadas de señal dinámica)\n",
        "    def safe_corr(a, b):\n",
        "        if len(a) < 2 or len(b) < 2:\n",
        "            return np.nan\n",
        "        return float(np.corrcoef(a, b)[0,1])\n",
        "\n",
        "    row = {\n",
        "        \"dialog_id\": i,\n",
        "        \"conv_id\": d.get(\"conv_id\", None),\n",
        "        \"n_turns\": n_turns,\n",
        "\n",
        "        # Señales (para inspección / figuras)\n",
        "        \"C_dyn\": C_dyn.tolist(),\n",
        "        \"C_base\": C_base.tolist(),\n",
        "        \"delta_C_dyn\": delta.tolist(),\n",
        "        \"break_positions\": breaks.tolist(),\n",
        "        \"break_threshold_delta\": thr,\n",
        "        \"n_breaks\": int(len(breaks)),\n",
        "\n",
        "        # Resúmenes real\n",
        "        \"mean_Cdyn\": float(np.mean(C_dyn)),\n",
        "        \"mean_Cbase\": float(np.mean(C_base)),\n",
        "        \"auc_Cdyn\": float(np.sum(C_dyn)),\n",
        "        \"vol_Cdyn\": float(np.std(C_dyn)),\n",
        "        \"vol_Cbase\": float(np.std(C_base)),\n",
        "        \"corr_dyn_base\": safe_corr(C_dyn, C_base),\n",
        "\n",
        "        # Control shuffled (resúmenes)\n",
        "        \"mean_Cdyn_sh\": float(np.mean(C_dyn_sh)),\n",
        "        \"mean_Cbase_sh\": float(np.mean(C_base_sh)),\n",
        "        \"auc_Cdyn_sh\": float(np.sum(C_dyn_sh)),\n",
        "        \"vol_Cdyn_sh\": float(np.std(C_dyn_sh)),\n",
        "        \"vol_Cbase_sh\": float(np.std(C_base_sh)),\n",
        "        \"corr_dyn_base_sh\": safe_corr(C_dyn_sh, C_base_sh),\n",
        "        \"n_breaks_sh\": int(len(breaks_sh)),\n",
        "\n",
        "        # Diferencias (lo que quieres mostrar en Results)\n",
        "        \"d_mean_Cdyn\": float(np.mean(C_dyn) - np.mean(C_dyn_sh)),\n",
        "        \"d_auc_Cdyn\": float(np.sum(C_dyn) - np.sum(C_dyn_sh)),\n",
        "        \"d_vol_Cdyn\": float(np.std(C_dyn) - np.std(C_dyn_sh)),\n",
        "        \"d_n_breaks\": int(len(breaks) - len(breaks_sh)),\n",
        "    }\n",
        "\n",
        "    results.append(row)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Mk6thyDcfgQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"N dialogs:\", len(df))\n",
        "print(\"\\n=== REAL vs SHUFFLED (promedios) ===\")\n",
        "print(\"mean_Cdyn:\", df[\"mean_Cdyn\"].mean(), \" | shuffled:\", df[\"mean_Cdyn_sh\"].mean())\n",
        "print(\"auc_Cdyn:\", df[\"auc_Cdyn\"].mean(),   \" | shuffled:\", df[\"auc_Cdyn_sh\"].mean())\n",
        "print(\"vol_Cdyn:\", df[\"vol_Cdyn\"].mean(),   \" | shuffled:\", df[\"vol_Cdyn_sh\"].mean())\n",
        "print(\"n_breaks:\", df[\"n_breaks\"].mean(),   \" | shuffled:\", df[\"n_breaks_sh\"].mean())\n",
        "\n",
        "print(\"\\n=== DIFERENCIAS (real - shuffled) ===\")\n",
        "print(\"d_mean_Cdyn mean:\", df[\"d_mean_Cdyn\"].mean())\n",
        "print(\"d_auc_Cdyn  mean:\", df[\"d_auc_Cdyn\"].mean())\n",
        "print(\"d_vol_Cdyn  mean:\", df[\"d_vol_Cdyn\"].mean())\n",
        "print(\"d_n_breaks  mean:\", df[\"d_n_breaks\"].mean())\n",
        "\n",
        "print(\"\\n% diálogos con d_auc_Cdyn > 0:\", (df[\"d_auc_Cdyn\"] > 0).mean())\n"
      ],
      "metadata": {
        "id": "CEkcBHqMf27U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,4))\n",
        "plt.hist(df[\"mean_Cdyn\"], bins=30, alpha=0.6, label=\"Real mean C_dyn\")\n",
        "plt.hist(df[\"mean_Cdyn_sh\"], bins=30, alpha=0.6, label=\"Shuffled mean C_dyn\")\n",
        "plt.title(\"Distribution of mean dynamic coherence: Real vs Shuffled\")\n",
        "plt.xlabel(\"mean C_dyn\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(9,4))\n",
        "plt.hist(df[\"d_auc_Cdyn\"], bins=30, alpha=0.8)\n",
        "plt.title(\"ΔAUC(C_dyn) = Real - Shuffled\")\n",
        "plt.xlabel(\"d_auc_Cdyn\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9-Nj-Ze-f-aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dialog_signals(C_dyn, C_base, breaks, title=\"\"):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(C_dyn, label=\"C_dyn\")\n",
        "    plt.plot(C_base, \"--\", alpha=0.6, label=\"C_base (local)\")\n",
        "    for b in breaks:\n",
        "        plt.axvline(b, alpha=0.25)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"t\")\n",
        "    plt.ylabel(\"cosine sim\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Selecciona el dialogo con mayor ΔAUC\n",
        "best_id = int(df.sort_values(\"d_auc_Cdyn\", ascending=False).iloc[0][\"dialog_id\"])\n",
        "d = dialogs[best_id]\n",
        "\n",
        "# Recalcula señales para plot (o usa las guardadas)\n",
        "C_dyn = np.array(df.loc[df.dialog_id==best_id, \"C_dyn\"].values[0])\n",
        "C_base = np.array(df.loc[df.dialog_id==best_id, \"C_base\"].values[0])\n",
        "breaks = np.array(df.loc[df.dialog_id==best_id, \"break_positions\"].values[0])\n",
        "\n",
        "plot_dialog_signals(C_dyn, C_base, breaks, title=f\"BEST dialog_id={best_id} | ΔAUC={df.loc[df.dialog_id==best_id,'d_auc_Cdyn'].values[0]:.3f}\")\n",
        "\n",
        "print(\"Dialog text:\")\n",
        "for t, utt in enumerate(d[\"dialog\"]):\n",
        "    print(f\"{t:02d}: {utt}\")\n",
        "print(\"Break positions:\", breaks.tolist())\n"
      ],
      "metadata": {
        "id": "dYrJDby3gGMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"dynamic_coherence_results_scaled_with_shuffle.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"dynamic_coherence_results_scaled_with_shuffle.csv\")\n"
      ],
      "metadata": {
        "id": "iu90InQOgT4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
